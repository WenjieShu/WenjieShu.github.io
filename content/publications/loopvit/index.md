---
title: "Thinking in Loops: Scaling Visual ARC with Looped Transformers"
authors:
  - admin

date: "2025-12-13T00:00:00Z"
publishDate: "2025-12-13T00:00:00Z"

publication_types: ["article"]
publication: "Blog / Preprint"
publication_short: "Blog"

abstract: We introduce Loop-ViT, a weight-tied (looped) transformer for Visual ARC that scales reasoning via iterative inference. By trading model width for “thinking time”, Loop-ViT reaches a new Pareto frontier on ARC-AGI, achieving strong accuracy with significantly fewer parameters.
summary: Looped (weight-tied) Transformers for Visual ARC—scale reasoning with “thinking time”.

tags:
  - Visual Reasoning
  - ARC
  - Transformers

featured: true

links:
  - type: website
    url: "https://hickory-stork-b84.notion.site/Thinking-in-Loops-Scaling-Visual-ARC-with-Looped-Transformers-2c8f56a03c7f8098aa7ae477cfbb93ca?pvs=74"
# 如果后续有 arXiv / PDF / Code，再在这里加：
#  - type: preprint
#    provider: arxiv
#    id: xxxxx.xxxxx
#  - type: code
#    url: https://github.com/...

image:
  filename: feature.jpg
  caption: ''
  focal_point: ''
  preview_only: false

projects: []
slides: ""
---

Preprint / blog post.

